\chapter{基于卷积神经网络的影评分类实验}
\section{数据集与预处理}
\subsection{数据的获取与概况}
本论文采用的数据集是来自豆瓣的中文影评数据。使用微软必应（Bing）搜索的Cosmos分布式处理平台获取。来自Cosmos的数据是原始的HTML 文本，使用HtmlAgility库对其进行解析，提取出有用的影评、评分等信息，整理成JSON格式的文件。数据的基本信息如表格\ref{tab:comment count}所示。

\begin{table}[H]
\centering
\caption{数据数量表格} \label{tab:comment count}
\begin{tabular}{c|c|c|c}
    \hline
    全部短评数量 & 全部长评数量 & 短评来源用户数量 & 短评对应电影数量\\
    \hline
    124591 & 100000 & 42517 & 4887\\
    \hline
\end{tabular}
\end{table}

整理生成的短评数据示例如表格\ref{tab:comment format}所示。
\begin{table}[H]
\centering
\caption{短评数据示例} \label{tab:comment format}
\begin{tabular}{c|c|c|c|c|c|c}
    \hline
    Text & Username & Rate & Cid & Vote & MovieName & MovieId\\
    \hline
    这么高分我有点不懂 & X.Lee & 3 & 1005243594 & 12 & 拿起枪的简 & 10760385\\
    \hline
\end{tabular}
\end{table}

短评数据每条的长度不超过140个字符，每条都带有对应评分（1到5星）；长评数据没有字数限制，同样每条都包括1到5星的评分。

选择来自豆瓣的中文影评作为语料的优势在于，短评和长评都可以看作有标注的数据，这就意味着我们不再需要再人工地对数据进行标注就可以在它们上面进行有监督的学习。此外，豆瓣的短评有长度的限制，易于转换为固定大小的输入矩阵，故我们使用短评作为主要的实验数据。对于获取到的长评数据，虽然它们也是有标注的数据，但由于它们之间长度相差很大，而且相对于情感信息比较密集的短评，长评中可能有很多谈论具体电影情节的，不带情感色彩的内容。所以本论文不直接使用长评数据进行实验，而是使用他们进行了词嵌入的训练。因为长评数据本身的数据量很大，其语境和用语习惯与短评非常接近，所以使用它们作为训练词嵌入的语料非常适合。

\subsection{分词与训练词嵌入}
获得了JSON格式的数据后，由于JSON中的Text域是原始的短评文本，所以还需要进行分词和训练词嵌入才能将这些数据转化为神经网络可以接受的形式。本论文采用的中文分词工具是斯坦福大学自然语言处理研究组的Stanford Word Segmenter，该分词工具基于的算法是使用条件随机场（Conditional Random Field）去做sequence model。

将短评数据和长评数据进行分词后，将其作为输入数据进行词嵌入的训练。训练词嵌入采用的算法是基于Continuous Bag of Word的Word2vec，这是一种高效率的词嵌入训练算法。本论文使用gensim库中对Word2vec的实现，选取词向量长度为100，从短评和长评数据中训练出了中文词语的词嵌入。

\subsection{实验设置}
本论文的实验分为两种，第一种是由中文电影短评预测该短评对应的评分（1到5星），本论文以短文本五分类的方法来实现对影评的预测；第二种是将五分类的中的3星评论去除，以1星和二星评论作为负面评论，四星和五星评论作为正面评论，由短评的内容预测其评论的倾向（正面还是负面），将问题转化为个短文本二分类来做。

在使用短评数据进行实验之前，我对短评根据其作者发布的影评数量进行了筛选，只保留了发表影评数量超过5的较活跃用户的影评。符合要求的影评共67255篇。抽取其中60000篇，进行了shuffle后按表格\ref{tab:data divide}划分了训练集，验证集和测试集（由于第二类实验需要去除三星的评论，故第二类实验的数据规模与第一类有所区别）

\begin{table}[H]
\centering
\caption{实验数据划分表格} \label{tab:data divide}
\begin{tabular}{c|c|c|c}
    \hline
     &训练集 & 验证集 & 测试集\\
    \hline
    评分预测实验 & 40000 & 10000 & 10000\\
    \hline
    二分类实验 & 28204 & 7059 & 7016\\
    \hline
\end{tabular}
\end{table}



\section{不同的卷积神经网络结构}
对于实验中的所有神经网络模型，均采用每个尺寸128个卷积核的设置。卷积核宽度固定等于词向量宽度，如卷积核长度为1、2、3，则长度为1、2、3 的卷积核各有128个，共384个不同的卷积核；在输入数据和pooling层后各设置一个dropout层，dropout的比率在0.0，0.3，0.5这三个档位进行网格实验，选出最优的一组。

实验设置在卷积神经网络的输入数据如何断句、通道数以及卷积网络的层数等超参数的设置上有所分化，主要分为以下几类实验：
\subsection{单层单通道}
结构如第三章中所述，只有一层卷积层，卷积的输出经过pooling和dropout直接传给最后进行分类的全连接Softmax只使用一个词嵌入，故卷积神经网络的输入的第三维宽度只有一，对应图像数据只有一个通道。这里的词嵌入层也作为神经网络的一部分，词向量的值也会通过backpropagation更新。

我们使用单层单通道网络在词语层面（使用中文分词器断句）和字层面（在每个字断句）的输入上都进行了实验，其中词语层面的词嵌入使用Word2vec的训练结果初始化，字层面则随机初始化。

\subsection{单层双通道}
同样只有一层卷积层，但有两个词嵌入，故传给卷积层的输入第三维大小为2，即有两个通道。这两个词嵌入都使用Word2vec的训练结果初始化，其差别在于只有其中一个在训练过程中保持更新，另一个则始终不变。单层双通道只在词语层面的输入上进行了实验。

\subsection{双层卷积神经网络}
使用两个卷积层，在字层面的输入上进行实验。旨在第一层完成字组合的特征提取，第二层提取更高层面的特征。

\section{Baseline 实验}
本论文进行了三个baseline实验用作对比和分析。分别为朴素贝叶斯分类器，基于Tf.idf特征抽取的支撑向量机，和LSTM神经网络。由于在本文的第二章文本情感分析已经对baseline方法的基本原理进行了介绍，这里只说明具体的实验设置。

朴素贝叶斯分类器使用基于计数的方法计算$P(w_i|C)$和$P(C)$。对于单词的出现次数设置阈值10，即一个单词只有在训练数据中出现的次数超过十次才能被用在预测中。具体的概率的计算方法和算法流程见算法\ref{Naive Bayes}。

支撑向量机使用Tf.idf来进行特征抽取，将句子转化为一个一维的向量。对于Tf.idf的词典设置阈值50，因为向量化的结果的长度等于词典大小，故需要选取一个比较高的阈值以压缩向量长度，选取50为阈值得到的向量长度约2000。使用RBF的核函数，Soft Margin的支撑向量机设置。对于评分预测的五分类的实验，使用one-agains-all的方法，将支撑向量机由二分类拓展为5分类。具体的算法流程见算法\ref{SVM}。

LSTM神经网络使用Tensorflow实现。输入数据为经过词嵌入的得到的词向量序列，单层的LSTM之后，经过一个平均值池化（mean-pooling），对每个词向量的输出取平均值，得到一个长度为隐藏层宽度的一维向量。该一维向量再通过一个Softmax，得到分类的预测结果。

\section{实验结果与分析}
Baseline实验结果如表格\ref{tab:results base}所示。

\begin{table}[H]
\centering
\caption{Baseline实验结果} \label{tab:results base}
\begin{tabular}{c|c|c|c}
    \hline
      & Naive Bayes & SVM & LSTM \\
    \hline
    评分预测（五分类）实验 & 41.54\% & 38.7\% & 43.62\% \\
    \hline
    二分类实验 & 79.64\% & 78.31\% & 81.77\% \\
    \hline
\end{tabular}
\end{table}
卷积神经网络评分预测（五分类实验）实验结果如表格\ref{tab:results5}所示、二分类预测实验结果如表格\ref{tab:results2} 所示。
\begin{table}[H]
\centering
\caption{评分预测实验准确率结果} \label{tab:results5}
\begin{tabular}{c|c|c|c|c}
    \hline
    Filters Sizes & CNN\_char & CNN & CNN\_2\_channel & CNN\_2\_layer\\
    \hline
    1 & 40.41\% & 43.04\% & - & - \\
    \hline
    1,2 & 42.11\% & 44.12\% & 43.29\% & 40.61\% \\
    \hline
    1,2,3 & 42.49\% & 43.28\% & - & - \\
    \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{二分类实验结果} \label{tab:results2}
\begin{tabular}{c|c|c|c|c}
    \hline
    Filters Sizes & CNN\_char & CNN & CNN\_2\_channel & CNN\_2\_layer\\
    \hline
    1 & 77.89\% & 81.42\% & - & - \\
    \hline
    1,2 & 79.74\% & 82.05\% & 81.33\% & 77.29\% \\
    \hline
    1,2,3 & 80.47\% & 81.50\% & - & - \\
    \hline
\end{tabular}
\end{table}

可以看到使用中文分词器分词的效果要好于按字断句，说明对中文语言文本分词的确可以提取出文本中很多的特征。而基于字断句的话，在训练数据不非常大的情况下（40000句仍然只能算比较少的数据量），或是模型复杂程度不够高的情况下，可能会导致一些信息或特征无法被提取出来，因而导致结果不如分词后的数据。但同时也可以注意到，在卷积核的设置包含了3或4这样比较大的窗口时，基于字断句的输入也会有很好的效果。这说明了说明卷积神经网络的确有提取局部特征（在这里体现为提取出字的组合的特征）的能力。

对于同一卷积神经网络结果，不同的卷积核设置也会明显地影响实验结果。对于输入使用分词器断句的实验，准确率在卷积核长度达到2时达到最大，加上长度为3的卷积核准确率反而下降；对于输入使用按字断句的实验，加上长度为3的卷积核后准确率得到了提高，但再加上长度为4的卷积核后（数据未列在上表上）准确率也下降了。给处理文本问题的卷积神经网络增加更大的卷积核可以看作一种Tradeoff，一方面增加更大的卷积核有可能提取出更多的句子特征，另一方面，这样也会使整个模型更加容易过拟合。实验结果表明，在进行了分词的数据上，连续三个中文词语中可以提取的特征已经很少，由此带来的“更容易过拟合”的缺点对结果的影响甚至超过了提取三个连续词语的特征带来的影响。

单层双通道的模型也取得了很好的实验结果，但其最好的结果没有超过单层单通道的最好实验结果。这与我们开始时的期望略有出入，可能是由于双通道的模型更容易过拟合。双层卷积层模型的结果也超过了baseline算法，但落后于单层卷积层的两种模型。这与图像数据领域的结果有很大差别，可能是因为文本数据每个单词相较于图像数据的像素，包含的信息要多得多。因此，即使在单层卷积层的模型也可以提取出很多的信息，也会有很好的结果。而多层之后，反而由于抽象的层数太高、过拟合的机会增大，可能会导致效果反而不如单层的网络。

另外也可以注意到，五分类问题的结果准确率普遍比较低，不超过45\%。这是由于对影评进行五分类本身是一个比较困难的问题，与本论文数据集相近的SST-1数据集（同样是影评数据，分为五类，分别为非常负面、负面、中立、正面和非常正面），目前最前沿的成果也只能达到48.7\%的准确率。这个问题准确率难以提得很高是因为每个影评者自己的指标不同，同样一句影评，对于一些人来说会选择给四星，另一些人则会给五星、三星。此外，中间三档影评的区分度很低。本论文使用的数据集未经过人工筛选，只根据作者发过的影评数设置了一个阈值。故数据集中可能存在评论与打分不符，或是一些没有意义的垃圾信息。这些评论也会对结果产生影响。

\begin{table}
\centering
\caption{Confusion Matrix} \label{tab:confusion}
\begin{tabular}{c|c|c|c|c|c}
    \hline
     & 1 & 2 & 3 & 4 & 5\\
    \hline
    1 & 0 & 306 & 166 & 86 & 61\\
    \hline
    2 & 229 & 0 & 303 & 79 & 22 \\
    \hline
    3 & 280 & 687 & 0 & 992 & 340 \\
    \hline
    1 & 59 & 127 & 647 & 0 & 587\\
    \hline
    1 & 43 & 53 & 153 & 368 & 0\\
    \hline
\end{tabular}
\end{table}

表格\ref{tab:confusion}是五分类问题最后结果的confusion matrix，即预测错误的分布。其横坐标为Ground Truth，纵坐标为预测值。可以看到，大多数的错误分布在主对角线附近，即出现在相邻的两个分段。尤其是中间二、三、四三个阶段，出现的错误非常多。这印证了我们上一段的分析。

因为五分类的结果准确率较低，难以应用在实际问题中。我们又增加了二分类的试验，可以看到，二分类实验的准确率很高，达到了82\%以上。同时可以注意到，各种模型在二分类问题上的相对表现与五分类的相当，即五分类问题中表现好的模型，在二分类中仍有很好的表现。没有出现只在某一个问题上表现特别好或特别差的异常现象，实验结果与预期相符。

\section{小结}
本章对论文所做的工作进行了说明。首先说明了数据的来源，对数据的预处理，已经实验的总体设置；然后说明了实现的不同神经网络结构的区别；之后，说明了baseline实验的设置；最后，对实验结果进行了总结和分析。比较了卷积神经网络的不同卷积核选取带来的结果差异；比较和分析了单层单通道和更复杂网络结构的实验结果；具体分析了为什么评分预测的准确率较低。
